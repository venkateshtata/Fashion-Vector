2021-10-16 20:39:28,121 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2021-10-16 20:39:28,160 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2021-10-16 20:39:28,252 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.4.2
TS Home: /home/venkatesh/.local/lib/python3.8/site-packages
Current directory: /home/venkatesh/Desktop/vector_assignment/Inference_Server
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 8
Max heap size: 3994 M
Python executable: /usr/bin/python3.8
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/venkatesh/Desktop/vector_assignment/Inference_Server/model_store
Initial Models: fashion=model_store/fashion.mar
Log dir: /home/venkatesh/Desktop/vector_assignment/Inference_Server/logs
Metrics dir: /home/venkatesh/Desktop/vector_assignment/Inference_Server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/venkatesh/Desktop/vector_assignment/Inference_Server/model_store
Model config: N/A
2021-10-16 20:39:28,257 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model_store/fashion.mar
2021-10-16 20:39:28,370 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model fashion
2021-10-16 20:39:28,370 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model fashion
2021-10-16 20:39:28,370 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model fashion loaded.
2021-10-16 20:39:28,370 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: fashion, count: 1
2021-10-16 20:39:28,379 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2021-10-16 20:39:28,795 [DEBUG] W-9000-fashion_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-fashion_1.0 State change null -> WORKER_STARTED
2021-10-16 20:39:28,798 [INFO ] W-9000-fashion_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2021-10-16 20:39:30,493 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2021-10-16 20:39:30,508 [INFO ] Thread-0 org.pytorch.serve.ModelServer - Unregistering model fashion version 1.0
2021-10-16 20:39:30,509 [DEBUG] Thread-0 org.pytorch.serve.wlm.ModelVersionedRefs - Removed model: fashion version: 1.0
2021-10-16 20:39:30,509 [DEBUG] Thread-0 org.pytorch.serve.wlm.WorkerThread - W-9000-fashion_1.0 State change WORKER_STARTED -> WORKER_SCALED_DOWN
2021-10-16 20:39:30,509 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-fashion_1.0-stderr
2021-10-16 20:39:30,509 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-fashion_1.0-stdout
2021-10-16 20:39:30,509 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_SCALED_DOWN
2021-10-16 20:39:30,509 [DEBUG] Thread-0 org.pytorch.serve.job.Job - Waiting time ns: 0, Inference time ns: 1701861539
2021-10-16 20:39:30,510 [DEBUG] W-9000-fashion_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2021-10-16 20:39:30,510 [DEBUG] W-9000-fashion_1.0 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2021-10-16 20:39:30,510 [WARN ] W-9000-fashion_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: fashion, error: Worker died.
2021-10-16 20:39:30,510 [DEBUG] W-9000-fashion_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-fashion_1.0 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2021-10-16 20:39:30,510 [WARN ] W-9000-fashion_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-fashion_1.0-stderr
2021-10-16 20:39:30,510 [WARN ] W-9000-fashion_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-fashion_1.0-stdout
2021-10-16 20:39:30,510 [DEBUG] W-9000-fashion_1.0 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2021-10-16 20:39:30,512 [INFO ] Thread-0 org.pytorch.serve.wlm.ModelManager - Model fashion unregistered.
2021-10-16 20:45:56,865 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2021-10-16 20:45:56,907 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2021-10-16 20:45:56,992 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.4.2
TS Home: /home/venkatesh/.local/lib/python3.8/site-packages
Current directory: /home/venkatesh/Desktop/vector_assignment/Inference_Server
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 8
Max heap size: 3994 M
Python executable: /usr/bin/python3.8
Config file: logs/config/20211016203930495-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/venkatesh/Desktop/vector_assignment/Inference_Server/model_store
Initial Models: fashion=model_store/fashion.mar
Log dir: /home/venkatesh/Desktop/vector_assignment/Inference_Server/logs
Metrics dir: /home/venkatesh/Desktop/vector_assignment/Inference_Server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/venkatesh/Desktop/vector_assignment/Inference_Server/model_store
Model config: N/A
2021-10-16 20:45:56,996 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20211016203930495-shutdown.cfg",
  "modelCount": 1,
  "created": 1634396970496,
  "models": {
    "fashion": {
      "1.0": {
        "defaultVersion": true,
        "marName": "fashion.mar",
        "minWorkers": 1,
        "maxWorkers": 1,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2021-10-16 20:45:57,002 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20211016203930495-shutdown.cfg
2021-10-16 20:45:57,002 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20211016203930495-shutdown.cfg validated successfully
2021-10-16 20:45:57,110 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model fashion
2021-10-16 20:45:57,110 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model fashion
2021-10-16 20:45:57,110 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model fashion
2021-10-16 20:45:57,111 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model fashion loaded.
2021-10-16 20:45:57,111 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: fashion, count: 1
2021-10-16 20:45:57,119 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2021-10-16 20:45:57,529 [DEBUG] W-9000-fashion_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-fashion_1.0 State change null -> WORKER_STARTED
2021-10-16 20:45:57,532 [INFO ] W-9000-fashion_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2021-10-16 20:45:59,222 [INFO ] main org.pytorch.serve.ModelServer - Torchserve stopped.
2021-10-16 20:45:59,232 [INFO ] Thread-0 org.pytorch.serve.ModelServer - Unregistering model fashion version 1.0
2021-10-16 20:45:59,233 [DEBUG] Thread-0 org.pytorch.serve.wlm.ModelVersionedRefs - Removed model: fashion version: 1.0
2021-10-16 20:45:59,233 [DEBUG] Thread-0 org.pytorch.serve.wlm.WorkerThread - W-9000-fashion_1.0 State change WORKER_STARTED -> WORKER_SCALED_DOWN
2021-10-16 20:45:59,234 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-fashion_1.0-stderr
2021-10-16 20:45:59,234 [WARN ] Thread-0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-fashion_1.0-stdout
2021-10-16 20:45:59,234 [INFO ] epollEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_SCALED_DOWN
2021-10-16 20:45:59,234 [DEBUG] W-9000-fashion_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_SCALED_DOWN
2021-10-16 20:45:59,234 [DEBUG] W-9000-fashion_1.0 org.pytorch.serve.wlm.WorkerThread - Shutting down the thread .. Scaling down.
2021-10-16 20:45:59,234 [WARN ] W-9000-fashion_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: fashion, error: Worker died.
2021-10-16 20:45:59,234 [DEBUG] W-9000-fashion_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-fashion_1.0 State change WORKER_SCALED_DOWN -> WORKER_STOPPED
2021-10-16 20:45:59,235 [WARN ] W-9000-fashion_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-fashion_1.0-stderr
2021-10-16 20:45:59,235 [WARN ] W-9000-fashion_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-fashion_1.0-stdout
2021-10-16 20:45:59,235 [DEBUG] W-9000-fashion_1.0 org.pytorch.serve.wlm.WorkerThread - Worker terminated due to scale-down call.
2021-10-16 20:45:59,237 [INFO ] Thread-0 org.pytorch.serve.wlm.ModelManager - Model fashion unregistered.
2021-10-16 20:46:24,007 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2021-10-16 20:46:24,057 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2021-10-16 20:46:24,140 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.4.2
TS Home: /home/venkatesh/.local/lib/python3.8/site-packages
Current directory: /home/venkatesh/Desktop/vector_assignment/Inference_Server
Temp directory: /tmp
Number of GPUs: 1
Number of CPUs: 8
Max heap size: 3994 M
Python executable: /usr/bin/python3.8
Config file: logs/config/20211016204559223-shutdown.cfg
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /home/venkatesh/Desktop/vector_assignment/Inference_Server/model_store
Initial Models: fashion=model_store/fashion.mar
Log dir: /home/venkatesh/Desktop/vector_assignment/Inference_Server/logs
Metrics dir: /home/venkatesh/Desktop/vector_assignment/Inference_Server/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 1
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /home/venkatesh/Desktop/vector_assignment/Inference_Server/model_store
Model config: N/A
2021-10-16 20:46:24,145 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Started restoring models from snapshot {
  "name": "20211016204559223-shutdown.cfg",
  "modelCount": 1,
  "created": 1634397359223,
  "models": {
    "fashion": {
      "1.0": {
        "defaultVersion": true,
        "marName": "fashion.mar",
        "minWorkers": 1,
        "maxWorkers": 1,
        "batchSize": 1,
        "maxBatchDelay": 100,
        "responseTimeout": 120
      }
    }
  }
}
2021-10-16 20:46:24,150 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Validating snapshot 20211016204559223-shutdown.cfg
2021-10-16 20:46:24,151 [INFO ] main org.pytorch.serve.snapshot.SnapshotManager - Snapshot 20211016204559223-shutdown.cfg validated successfully
2021-10-16 20:46:24,275 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model fashion
2021-10-16 20:46:24,275 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model fashion
2021-10-16 20:46:24,276 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model fashion
2021-10-16 20:46:24,276 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model fashion loaded.
2021-10-16 20:46:24,276 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: fashion, count: 1
2021-10-16 20:46:24,285 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.
2021-10-16 20:46:24,364 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2021-10-16 20:46:24,364 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: EpollServerSocketChannel.
2021-10-16 20:46:24,365 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2021-10-16 20:46:24,365 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.
2021-10-16 20:46:24,366 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2021-10-16 20:46:24,512 [WARN ] pool-2-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2021-10-16 20:46:24,747 [DEBUG] W-9000-fashion_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-fashion_1.0 State change null -> WORKER_STARTED
2021-10-16 20:46:24,749 [INFO ] W-9000-fashion_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /tmp/.ts.sock.9000
2021-10-16 20:46:26,911 [INFO ] W-9000-fashion_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2135
2021-10-16 20:46:26,911 [DEBUG] W-9000-fashion_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-fashion_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2021-10-16 20:46:42,253 [INFO ] W-9000-fashion_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 7
2021-10-16 20:46:42,254 [DEBUG] W-9000-fashion_1.0 org.pytorch.serve.job.Job - Waiting time ns: 187555, Backend time ns: 8933636
2021-10-16 20:47:14,632 [INFO ] W-9000-fashion_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 17
2021-10-16 20:47:14,632 [DEBUG] W-9000-fashion_1.0 org.pytorch.serve.job.Job - Waiting time ns: 132088, Backend time ns: 17690511
2021-10-16 21:03:05,451 [INFO ] W-9000-fashion_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 9
2021-10-16 21:03:05,452 [DEBUG] W-9000-fashion_1.0 org.pytorch.serve.job.Job - Waiting time ns: 131056, Backend time ns: 11433244
2021-10-16 21:03:22,039 [INFO ] W-9000-fashion_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 8
2021-10-16 21:03:22,040 [DEBUG] W-9000-fashion_1.0 org.pytorch.serve.job.Job - Waiting time ns: 139704, Backend time ns: 9046012
2021-10-16 21:07:21,970 [INFO ] W-9000-fashion_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 9
2021-10-16 21:07:21,971 [DEBUG] W-9000-fashion_1.0 org.pytorch.serve.job.Job - Waiting time ns: 169300, Backend time ns: 10936568
2021-10-16 21:09:27,273 [INFO ] W-9000-fashion_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 7
2021-10-16 21:09:27,274 [DEBUG] W-9000-fashion_1.0 org.pytorch.serve.job.Job - Waiting time ns: 120017, Backend time ns: 8111414
2021-10-16 21:10:21,716 [INFO ] W-9000-fashion_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 8
2021-10-16 21:10:21,717 [DEBUG] W-9000-fashion_1.0 org.pytorch.serve.job.Job - Waiting time ns: 163443, Backend time ns: 10199502
